{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e977ba-0f02-4b34-89d4-41fbfb478409",
   "metadata": {},
   "source": [
    "# Finding Data\n",
    "\n",
    "## SDK Code Exercise\n",
    "**Software development kits (SDKs)** provide a set of tools, libraries, documentation, code samples, and more that allow developers to create software applications. SDKs often include APIs, which we’ll dig into a little bit below. In research and technology development, SDKs are often provided by organizations or companies that are hosting data, as a way of providing  examples and tools to work with the data.\n",
    "\n",
    "One great example of an SDK in neuroscience is the [Allen Institute SDK](https://allensdk.readthedocs.io). This SDK provides researchers up-to-date access to data and code that is hot off the presses from the Allen Institute, based in Seattle, Washington.\n",
    "\n",
    "For example, here’s how you can — in just a few lines of code — start working with electrophysiology data from the Allen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef88e340-d9d4-4292-b90d-f5e670433f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allensdk not found, installing now...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: allensdk in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (2.16.2)\r\n",
      "Requirement already satisfied: psycopg2-binary in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.9.10)\r\n",
      "Requirement already satisfied: hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.* in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (4.1.0)\r\n",
      "Requirement already satisfied: h5py in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.14.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.10.3)\r\n",
      "Requirement already satisfied: numpy<1.24 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.23.5)\r\n",
      "Requirement already satisfied: pandas==1.5.3 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.5.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.1.6)\r\n",
      "Requirement already satisfied: scipy<1.11 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.10.1)\r\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.17.0)\r\n",
      "Requirement already satisfied: pynrrd in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.1.3)\r\n",
      "Requirement already satisfied: future in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.0.0)\r\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.32.4)\r\n",
      "Requirement already satisfied: requests-toolbelt in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.0.0)\r\n",
      "Requirement already satisfied: simplejson in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.20.1)\r\n",
      "Requirement already satisfied: scikit-image in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.24.0)\r\n",
      "Requirement already satisfied: scikit-build in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.18.1)\r\n",
      "Requirement already satisfied: statsmodels in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.14.5)\r\n",
      "Requirement already satisfied: simpleitk in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.5.2)\r\n",
      "Requirement already satisfied: argschema in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.0.4)\r\n",
      "Requirement already satisfied: glymur in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.14.3)\r\n",
      "Requirement already satisfied: xarray<2023.2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2023.1.0)\r\n",
      "Requirement already satisfied: pynwb in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.8.3)\r\n",
      "Requirement already satisfied: tables in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.10.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.13.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.12.14)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (4.67.1)\r\n",
      "Requirement already satisfied: ndx-events in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (0.2.1)\r\n",
      "Requirement already satisfied: boto3 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (1.39.4)\r\n",
      "Requirement already satisfied: semver in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (3.0.4)\r\n",
      "Requirement already satisfied: cachetools in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (6.1.0)\r\n",
      "Requirement already satisfied: sqlalchemy in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.0.41)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from allensdk) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from pandas==1.5.3->allensdk) (2025.2)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from xarray<2023.2.0->allensdk) (25.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonschema>=3.2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (4.24.0)\r\n",
      "Requirement already satisfied: ruamel-yaml>=0.16 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (0.18.14)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from jsonschema>=3.2.0->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from jsonschema>=3.2.0->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (2025.4.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from jsonschema>=3.2.0->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from jsonschema>=3.2.0->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (0.26.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=3.2.0->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (4.14.1)\r\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from ruamel-yaml>=0.16->hdmf!=3.5.*,!=3.6.*,!=3.7.*,!=3.8.*->allensdk) (0.2.12)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (1.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from aiohttp->allensdk) (1.20.1)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->allensdk) (3.10)\r\n",
      "Requirement already satisfied: marshmallow<4.0,>=3.0.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from argschema->allensdk) (3.26.1)\r\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from argschema->allensdk) (6.0.2)\r\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.4 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from boto3->allensdk) (1.39.4)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from boto3->allensdk) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from boto3->allensdk) (0.13.0)\r\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from botocore<1.40.0,>=1.39.4->boto3->allensdk) (2.5.0)\r\n",
      "Requirement already satisfied: lxml in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from glymur->allensdk) (6.0.0)\r\n",
      "Requirement already satisfied: pillow in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from glymur->allensdk) (11.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from jinja2->allensdk) (3.0.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from matplotlib->allensdk) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from matplotlib->allensdk) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from matplotlib->allensdk) (4.58.5)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from matplotlib->allensdk) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from matplotlib->allensdk) (3.2.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from requests->allensdk) (3.4.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from requests->allensdk) (2025.7.9)\r\n",
      "Requirement already satisfied: distro in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-build->allensdk) (1.9.0)\r\n",
      "Requirement already satisfied: setuptools>=42.0.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-build->allensdk) (80.9.0)\r\n",
      "Requirement already satisfied: wheel>=0.32.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-build->allensdk) (0.45.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-image->allensdk) (3.5)\r\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-image->allensdk) (2.37.0)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-image->allensdk) (2025.6.11)\r\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from scikit-image->allensdk) (0.4)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from statsmodels->allensdk) (1.0.1)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from tables->allensdk) (2.11.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from tables->allensdk) (9.0.0)\r\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from tables->allensdk) (2.7.1)\r\n",
      "Requirement already satisfied: ndindex>=1.4 in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from blosc2>=2.3.0->tables->allensdk) (1.10.0)\r\n",
      "Requirement already satisfied: msgpack in /opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages (from blosc2>=2.3.0->tables->allensdk) (1.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "# Install the allensdk to your environment if needed (note you may need to restart session after this cell)\n",
    "try:\n",
    "    import allensdk\n",
    "    print(\"allensdk is already installed.\")\n",
    "except ImportError:\n",
    "    print(\"allensdk not found, installing now...\")\n",
    "    !pip install allensdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6885c9c-90e8-47b7-b416-4c5034004381",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allensdk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import pandas and the \"Cell Types Cache\" from the AllenSDK core package\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mallensdk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcell_types_cache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CellTypesCache\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Initialize the cache as 'ctc' (cell types cache)\u001b[39;00m\n\u001b[32m      6\u001b[39m ctc = CellTypesCache(manifest_file=\u001b[33m'\u001b[39m\u001b[33mcell_types/manifest.json\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'allensdk'"
     ]
    }
   ],
   "source": [
    "# Import pandas and the \"Cell Types Cache\" from the AllenSDK core package\n",
    "import pandas as pd\n",
    "from allensdk.core.cell_types_cache import CellTypesCache\n",
    "\n",
    "# Initialize the cache as 'ctc' (cell types cache)\n",
    "ctc = CellTypesCache(manifest_file='cell_types/manifest.json')\n",
    "\n",
    "# Download all electrophysiology features for all cells\n",
    "ephys_features = ctc.get_ephys_features()\n",
    "\n",
    "# Make it a dataframe & show the first 5 rows\n",
    "ef_df = pd.DataFrame(ephys_features)\n",
    "ef_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e22c1-409e-4cbf-9365-05246ac3089a",
   "metadata": {},
   "source": [
    "For now, this just shows you how easy it is to access some open neuroscience data! We'll come back to this particular dataset in a later chapter to play with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae476b4-5089-43f9-8b18-b819002a38a3",
   "metadata": {},
   "source": [
    "## API Code Exercise\n",
    "\n",
    "**Application programmer interfaces**, or APIs, allow programmatic access to many databases and tools. Many large organizations such as the National Institutes of Health will help upkeep APIs that enable researchers to conduct research using publicly available datasets.\n",
    "\n",
    "(It’s not worth worrying too much about the difference between APIs and SDKs — we’d generally encourage you to think about it as: SDKs contain much more than just APIs. An API provides the building blocks for software workflow, while an SDK is a pre-packaged collection of code and data that researchers can use to work with data easily and efficiently.)\n",
    "\n",
    "For example, a very popular bioinformatics tool called BLAST has an API that researchers can use to interact with -ohmics datasets, rather than downloading the BLAST database on their computer. BLAST is a tool to find similarities behind sequences of DNA. Likewise, a tool called ENTREZ allows researchers to programmatically search many National Center for Biotechnology Information (NCBI) databases.\n",
    "\n",
    "There isn’t one standard way of interacting with an API — each one works slightly differently. However, almost always you’ll need the help of a library called requests. This library allows you to retrieve information from a URL. \n",
    "\n",
    "In the code exercise below, we’ll use requests to search the Entrez database for the term “neural data science.” Within, we are using the URL and parameters (params) as informed by the documentation for the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8435c9-c1a2-4cb3-b655-844a167deef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': {'type': 'esearch', 'version': '0.3'},\n",
       " 'esearchresult': {'count': '41129',\n",
       "  'retmax': '20',\n",
       "  'retstart': '0',\n",
       "  'idlist': ['40590186',\n",
       "   '40590026',\n",
       "   '40589994',\n",
       "   '40589818',\n",
       "   '40588827',\n",
       "   '40588700',\n",
       "   '40588695',\n",
       "   '40588487',\n",
       "   '40588361',\n",
       "   '40588165',\n",
       "   '40587931',\n",
       "   '40587919',\n",
       "   '40586488',\n",
       "   '40586430',\n",
       "   '40586263',\n",
       "   '40585969',\n",
       "   '40585851',\n",
       "   '40585236',\n",
       "   '40584826',\n",
       "   '40583914'],\n",
       "  'translationset': [{'from': 'neural',\n",
       "    'to': '\"neural\"[All Fields] OR \"neuralization\"[All Fields] OR \"neuralize\"[All Fields] OR \"neuralized\"[All Fields] OR \"neuralizes\"[All Fields] OR \"neuralizing\"[All Fields] OR \"neurally\"[All Fields]'},\n",
       "   {'from': 'data science',\n",
       "    'to': '\"data science\"[MeSH Terms] OR (\"data\"[All Fields] AND \"science\"[All Fields]) OR \"data science\"[All Fields]'}],\n",
       "  'querytranslation': '(\"neural\"[All Fields] OR \"neuralization\"[All Fields] OR \"neuralize\"[All Fields] OR \"neuralized\"[All Fields] OR \"neuralizes\"[All Fields] OR \"neuralizing\"[All Fields] OR \"neurally\"[All Fields]) AND (\"data science\"[MeSH Terms] OR (\"data\"[All Fields] AND \"science\"[All Fields]) OR \"data science\"[All Fields])'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "term = \"neural data science\"\n",
    "params = {\"db\": \"pubmed\", \"term\": term,\"retmode\": \"json\"}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Show results of search\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30056b9-a8ef-4aa4-8969-23856e2ebfe1",
   "metadata": {},
   "source": [
    "In the output above, you can see the results of our search. When we published the book, there were about 41,000 papers. Can you see how many there are now? (Hint: look for `count`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b6c72-eb08-4174-8a7c-4826c1737d9c",
   "metadata": {},
   "source": [
    "## Webscraping Code Exercise\n",
    "We can use the requests module to scrape data from any website, actually. For example, if you want to scrape the very informative “iscaliforniaonfire.com” and show the results of this, you can write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c621038a-8d6c-4f0e-acde-5fabab107ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n<head>\\n<title>Is California On Fire?</title>\\n</head>\\n<body>\\n<h1>Yes</h1>\\nupdated: Tue Jul  1 12:39:15 2025 PDT\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get('http://iscaliforniaonfire.com/')\n",
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038815ac-c177-4c0e-b117-1d2c44084654",
   "metadata": {},
   "source": [
    "The output here is in html format, which we’d then need to parse if we wanted to scrape it for some purpose. We can import yet another package, poetically named BeautifulSoup, to organize this html output, search through it for a particular HTML tag, and cleanly print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0306d83d-aef6-4c54-bb01-fd3143a7515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import beautiful soup package\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "# Create the soup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find the HTML tag of interest and show results\n",
    "h1_content = soup.find('h1')\n",
    "h1_content.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf9e97-b103-4d0f-95b3-afb948575cdb",
   "metadata": {},
   "source": [
    "This website is very simple (and alarming, speaking as two people that live in California), so it’s quite simple to get to the point: yes, California is almost always on fire. Most websites aren’t so easy to scrape cleanly, and getting the exact information you need can be a bit tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb403f-6cfb-4676-9677-2c573472f39e",
   "metadata": {},
   "source": [
    "## PubMed Utilities Exercise\n",
    "\n",
    "As a neural data scientist, you likely won’t do a ton of web scraping, but these HTML (or XML, or JSON) parsing skills can come in handy in many different types of informatics. For example, if you’d like to work with the PubMed utilities mentioned above to pull abstracts of scientific articles around a particular search term, PubMed will return the results to you in XML by default. So, you need to know how to parse these results in order to do fun informatics work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beecb5b7-af9d-4fa4-8811-e368e753c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Biopython\n",
      "  Downloading biopython-1.85-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (from Biopython) (2.2.3)\n",
      "Downloading biopython-1.85-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: Biopython\n",
      "Successfully installed Biopython-1.85\n"
     ]
    }
   ],
   "source": [
    "# Install package that contains Entrez (you may need to restart session after doing so)\n",
    "!pip install Biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e7c559-8d03-4aa6-893d-ea6201850313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" ?>\\n<!DOCTYPE PubmedArticleSet PUBLIC \"-//NLM//DTD PubMedArticle, 1st January 2025//EN\" \"https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_250101.dtd\">\\n<PubmedArticleSet>\\n<PubmedArticle><MedlineCitation Status=\"MEDLINE\" Owner=\"NLM\" IndexingMethod=\"Automated\"><PMID Version=\"1\">36729258</PMID><DateCompleted><Year>2023</Year><Month>06</Month><Day>26</Day></DateCompleted><DateRevised><Year>2024</Year><Month>06</Month><Day>03</Day></DateRevised><Article PubModel=\"Print-Electronic\"><Journal><ISSN IssnType=\"Electronic\">1618-727X</ISSN><JournalIssue CitedMedium=\"Internet\"><Volume>36</Volume><Issue>3</Issue><PubDate><Year>2023</Year><Month>Jun</Month></PubDate></JournalIssue><Title>Journal of digital imaging</Title><ISOAbbreviation>J Digit Imaging</ISOAbbreviation></Journal><ArticleTitle>Ultrasound Prostate Segmentation Using Adaptive Selection Principal Curve and Smooth Mathematical Model.</ArticleTitle><Pagination><StartPage>947</StartPage><EndPage>963</EndPage><MedlinePgn>947-963</MedlinePgn></Pagination><ELocationID EIdType=\"doi\" ValidYN=\"Y\">10.1007/s10278-023-00783-3</ELocationID><Abstract><AbstractText>Accurate prostate segmentation in ultrasound images is crucial for the clinical diagnosis of prostate cancer and for performing image-guided prostate surgery. However, it is challenging to accurately segment the prostate in ultrasound images due to their low signal-to-noise ratio, the low contrast between the prostate and neighboring tissues, and the diffuse or invisible boundaries of the prostate. In this paper, we develop a novel hybrid method for segmentation of the prostate in ultrasound images that generates accurate contours of the prostate from a range of datasets. Our method involves three key steps: (1) application of a principal curve-based method to obtain a data sequence comprising data coordinates and their corresponding projection index; (2) use of the projection index as training input for a fractional-order-based neural network that increases the accuracy of results; and (3) generation of a smooth mathematical map (expressed via the parameters of the neural network) that affords a smooth prostate boundary, which represents the output of the neural network (i.e., optimized vertices) and matches the ground truth contour. Experimental evaluation of our method and several other state-of-the-art segmentation methods on datasets of prostate ultrasound images generated at multiple institutions demonstrated that our method exhibited the best capability. Furthermore, our method is robust as it can be applied to segment prostate ultrasound images obtained at multiple institutions based on various evaluation metrics.</AbstractText><CopyrightInformation>&#xa9; 2023. The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.</CopyrightInformation></Abstract><AuthorList CompleteYN=\"Y\"><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Peng</LastName><ForeName>Tao</ForeName><Initials>T</Initials><Identifier Source=\"ORCID\">0000-0003-0848-7901</Identifier><AffiliationInfo><Affiliation>School of Future Science and Engineering, Soochow University, Suzhou, China. sdpengtao401@gmail.com.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Health Technology and Informatics, The Hong Kong Polytechnic University, Hong Kong, China. sdpengtao401@gmail.com.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Radiation Oncology, UT Southwestern Medical Center, Dallas, TX, USA. sdpengtao401@gmail.com.</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Wu</LastName><ForeName>Yiyun</ForeName><Initials>Y</Initials><AffiliationInfo><Affiliation>Department of Ultrasound, Jiangsu Province Hospital of Chinese Medicine, Nanjing, Jiangsu, China.</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Zhao</LastName><ForeName>Jing</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Ultrasound, Tsinghua University Affiliated Beijing Tsinghua Changgung Hospital, Beijing, China.</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Wang</LastName><ForeName>Caishan</ForeName><Initials>C</Initials><AffiliationInfo><Affiliation>Department of Ultrasound, the Second Affiliated Hospital of Soochow University, Suzhou, Jiangsu, China.</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Wang</LastName><ForeName>Jin</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>School of Future Science and Engineering, Soochow University, Suzhou, China.</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\" EqualContrib=\"Y\"><LastName>Cai</LastName><ForeName>Jing</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Health Technology and Informatics, The Hong Kong Polytechnic University, Hong Kong, China.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI=\"D016428\">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType=\"Electronic\"><Year>2023</Year><Month>02</Month><Day>02</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>J Digit Imaging</MedlineTA><NlmUniqueID>9100529</NlmUniqueID><ISSNLinking>0897-1889</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI=\"D008297\" MajorTopicYN=\"N\">Male</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D006801\" MajorTopicYN=\"N\">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D011467\" MajorTopicYN=\"Y\">Prostate</DescriptorName><QualifierName UI=\"Q000000981\" MajorTopicYN=\"N\">diagnostic imaging</QualifierName></MeshHeading><MeshHeading><DescriptorName UI=\"D016571\" MajorTopicYN=\"N\">Neural Networks, Computer</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D011471\" MajorTopicYN=\"Y\">Prostatic Neoplasms</DescriptorName><QualifierName UI=\"Q000000981\" MajorTopicYN=\"N\">diagnostic imaging</QualifierName></MeshHeading><MeshHeading><DescriptorName UI=\"D014463\" MajorTopicYN=\"N\">Ultrasonography</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D008962\" MajorTopicYN=\"N\">Models, Theoretical</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D007091\" MajorTopicYN=\"N\">Image Processing, Computer-Assisted</DescriptorName><QualifierName UI=\"Q000379\" MajorTopicYN=\"N\">methods</QualifierName></MeshHeading></MeshHeadingList><KeywordList Owner=\"NOTNLM\"><Keyword MajorTopicYN=\"N\">Fractional-order-based neural network</Keyword><Keyword MajorTopicYN=\"N\">Mean shift clustering</Keyword><Keyword MajorTopicYN=\"N\">Principal curve</Keyword><Keyword MajorTopicYN=\"N\">Smooth mathematical model</Keyword><Keyword MajorTopicYN=\"N\">Ultrasound prostate segmentation</Keyword></KeywordList><CoiStatement>The authors declare no competing interests.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus=\"received\"><Year>2022</Year><Month>2</Month><Day>16</Day></PubMedPubDate><PubMedPubDate PubStatus=\"accepted\"><Year>2023</Year><Month>1</Month><Day>18</Day></PubMedPubDate><PubMedPubDate PubStatus=\"revised\"><Year>2022</Year><Month>12</Month><Day>15</Day></PubMedPubDate><PubMedPubDate PubStatus=\"medline\"><Year>2023</Year><Month>6</Month><Day>26</Day><Hour>6</Hour><Minute>42</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"pubmed\"><Year>2023</Year><Month>2</Month><Day>3</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"entrez\"><Year>2023</Year><Month>2</Month><Day>2</Day><Hour>11</Hour><Minute>20</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"pmc-release\"><Year>2024</Year><Month>6</Month><Day>1</Day></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType=\"pubmed\">36729258</ArticleId><ArticleId IdType=\"pmc\">PMC10287615</ArticleId><ArticleId IdType=\"doi\">10.1007/s10278-023-00783-3</ArticleId><ArticleId IdType=\"pii\">10.1007/s10278-023-00783-3</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Karimi D, Zeng Q, Mathur P, Avinash A, Mahdavi S, Spadinger I, Abolmaesumi P, Salcudean SE. Accurate and robust deep learning-based segmentation of the prostate clinical target volume in ultrasound images. Med. Image Anal. 2019;57:186&#x2013;196. doi: 10.1016/j.media.2019.07.005.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.media.2019.07.005</ArticleId><ArticleId IdType=\"pubmed\">31325722</ArticleId></ArticleIdList></Reference><Reference><Citation>Kollmeier MA. Combined brachytherapy and ultra-hypofractionated radiotherapy for intermediate-risk prostate cancer: Comparison of toxicity outcomes using a high-dose-rate (HDR) versus low-dose-rate (LDR) brachytherapy boost. Brachytherapy. 2022;21:599&#x2013;604. doi: 10.1016/j.brachy.2022.04.006.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.brachy.2022.04.006</ArticleId><ArticleId IdType=\"pmc\">PMC10372465</ArticleId><ArticleId IdType=\"pubmed\">35725549</ArticleId></ArticleIdList></Reference><Reference><Citation>Nouranian S, Ramezani M, Spadinger I, Morris WJ, Salcudean SE, Abolmaesumi P. Learning-Based Multi-Label Segmentation of Transrectal Ultrasound Images for Prostate Brachytherapy. IEEE Trans. Med. Imaging. 2016;35:921&#x2013;932. doi: 10.1109/TMI.2015.2502540.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TMI.2015.2502540</ArticleId><ArticleId IdType=\"pubmed\">26599701</ArticleId></ArticleIdList></Reference><Reference><Citation>Xu X, Sanford T, Turkbey B, Xu S, Wood BJ, Yan P. Shadow-consistent Semi-supervised Learning for Prostate Ultrasound Segmentation. IEEE Trans. Med. Imaging. 2022;41:1331&#x2013;1345. doi: 10.1109/TMI.2021.3139999.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TMI.2021.3139999</ArticleId><ArticleId IdType=\"pmc\">PMC9709821</ArticleId><ArticleId IdType=\"pubmed\">34971530</ArticleId></ArticleIdList></Reference><Reference><Citation>Rundo L, Han C, Nagano Y, Zhang J, Hataya R, Militello C, Tangherloni A, Nobile MS, Ferretti C, Besozzi D, Gilardi MC, Vitabile S, Mauri G, Nakayama H, Cazzaniga P. USE-Net: Incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets. Neurocomputing. 2019;365:31&#x2013;43. doi: 10.1016/j.neucom.2019.07.006.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.neucom.2019.07.006</ArticleId></ArticleIdList></Reference><Reference><Citation>Yang X, Zhan S, Xie D, Zhao H, Kurihara T. Hierarchical prostate MRI segmentation via level set clustering with shape prior. Neurocomputing. 2017;257:154&#x2013;163. doi: 10.1016/j.neucom.2016.12.071.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.neucom.2016.12.071</ArticleId></ArticleIdList></Reference><Reference><Citation>Salimi A, Pourmina MA, Moin M-S. Fully automatic prostate segmentation in MR images using a new hybrid active contour-based approach. Signal Image Video Process. 2018;12:1629&#x2013;1637. doi: 10.1007/s11760-018-1320-y.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1007/s11760-018-1320-y</ArticleId></ArticleIdList></Reference><Reference><Citation>Orlando N, Gyacskov I, Gillies DJ, Guo F, Romagnoli C, D&#x2019;Souza D, Cool DW, Hoover DA, Fenster A. Effect of dataset size, image quality, and image type on deep learning-based automatic prostate segmentation in 3D ultrasound. Phys. Med. Biol. 2022;67:074002. doi: 10.1088/1361-6560/ac5a93.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1088/1361-6560/ac5a93</ArticleId><ArticleId IdType=\"pubmed\">35240585</ArticleId></ArticleIdList></Reference><Reference><Citation>T. Peng, C. Tang, J. Wang, Prostate segmentation of ultrasound images based on interpretable-guided mathematical Model, in: Int. Conf. Multimed. Model. MMM, Springer, 2022: pp. 166&#x2013;177.</Citation></Reference><Reference><Citation>T. Peng, C. Tang, Y. Wu, J. Cai, Semi-automatic prostate segmentation from ultrasound images using machine learning and principal curve based on interpretable mathematical model expression, Front. Oncol. 12 (2022).</Citation><ArticleIdList><ArticleId IdType=\"pmc\">PMC9209717</ArticleId><ArticleId IdType=\"pubmed\">35747834</ArticleId></ArticleIdList></Reference><Reference><Citation>Shah SMS, Batool S, Khan I, Ashraf MU, Abbas SH, Hussain SA. Feature extraction through parallel Probabilistic Principal Component Analysis for heart disease diagnosis. Phys. Stat. Mech. Its Appl. 2017;482:796&#x2013;807. doi: 10.1016/j.physa.2017.04.113.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.physa.2017.04.113</ArticleId></ArticleIdList></Reference><Reference><Citation>Zhang J, Cui W, Guo X, Wang B, Wang Z. Classification of digital pathological images of non-Hodgkin&#x2019;s lymphoma subtypes based on the fusion of transfer learning and principal component analysis. Med. Phys. 2020;47:4241&#x2013;4253. doi: 10.1002/mp.14357.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1002/mp.14357</ArticleId><ArticleId IdType=\"pubmed\">32593219</ArticleId></ArticleIdList></Reference><Reference><Citation>Hastie T, Stuetzle W. Principal Curves. J. Am. Stat. Assoc. 1989;84:502&#x2013;516. doi: 10.1080/01621459.1989.10478797.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1080/01621459.1989.10478797</ArticleId></ArticleIdList></Reference><Reference><Citation>Kegl B, Linder T, Zeger K. Learning and design of principal curves. IEEE Trans. Pattern Anal. Mach. Intell. 2000;22:281&#x2013;297. doi: 10.1109/34.841759.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/34.841759</ArticleId></ArticleIdList></Reference><Reference><Citation>Correa Moraes EC, Ferreira DD, A principal curve-based method for data clustering, in, Int. Jt. Conf. Neural Netw. IJCNN, IEEE, Vancouver, BC. 2016;2016:3966&#x2013;3971.</Citation></Reference><Reference><Citation>Verbeek JJ, Vlassis N, Krose B. A k-segments algorithm for finding principal curves. Pattern Recognit. Lett. 2002;23:1009&#x2013;1017. doi: 10.1016/S0167-8655(02)00032-6.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/S0167-8655(02)00032-6</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng T, Wang Y, Xu TC, Shi L, Jiang J, Zhu S. Detection of Lung Contour with Closed Principal Curve and Machine Learning. J. Digit. Imaging. 2018;31:520&#x2013;533. doi: 10.1007/s10278-018-0058-y.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1007/s10278-018-0058-y</ArticleId><ArticleId IdType=\"pmc\">PMC6113140</ArticleId><ArticleId IdType=\"pubmed\">29450843</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng T, Wang Y, Xu TC, Chen X. Segmentation of Lung in Chest Radiographs Using Hull and Closed Polygonal Line Method. IEEE Access. 2019;7:137794&#x2013;137810. doi: 10.1109/ACCESS.2019.2941511.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/ACCESS.2019.2941511</ArticleId></ArticleIdList></Reference><Reference><Citation>T. Peng, C. Tang, Y. Wu, J. Cai, H-SegMed: A hybrid method for prostate segmentation in TRUS images via improved closed principal curve and improved enhanced machine learning, Int. J. Comput. Vis. 92 (2022).</Citation></Reference><Reference><Citation>Biau G, Fischer A. Parameter selection for principal curves. IEEE Trans. Inf. Theory. 2012;58:1924&#x2013;1939. doi: 10.1109/TIT.2011.2173157.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TIT.2011.2173157</ArticleId></ArticleIdList></Reference><Reference><Citation>Guo Y, &#x15e;eng&#xfc;r A, Akbulut Y, Shipley A. An effective color image segmentation approach using neutrosophic adaptive mean shift clustering. Measurement. 2018;119:28&#x2013;40. doi: 10.1016/j.measurement.2018.01.025.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.measurement.2018.01.025</ArticleId></ArticleIdList></Reference><Reference><Citation>Chen MR, Chen BP, Zeng G-Q, Lu KD, Chu P. An adaptive fractional-order BP neural network based on extremal optimization for handwritten digits recognition. Neurocomputing. 2020;391:260&#x2013;272. doi: 10.1016/j.neucom.2018.10.090.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.neucom.2018.10.090</ArticleId></ArticleIdList></Reference><Reference><Citation>Moraes ECC, Ferreira DD, Vitor GB, Barbosa BHG. Data clustering based on principal curves. Adv. Data Anal. Classif. 2020;14:77&#x2013;96. doi: 10.1007/s11634-019-00363-w.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1007/s11634-019-00363-w</ArticleId></ArticleIdList></Reference><Reference><Citation>R. Wu, B. Wang, A. Xu, Functional data clustering using principal curve methods, Commun. Stat. - Theory Methods. (2021) 1&#x2013;20.</Citation></Reference><Reference><Citation>Anand S, Mittal S, Tuzel O, Meer P. Semi-Supervised Kernel Mean Shift Clustering. IEEE Trans. Pattern Anal. Mach. Intell. 2014;36:1201&#x2013;1215. doi: 10.1109/TPAMI.2013.190.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TPAMI.2013.190</ArticleId><ArticleId IdType=\"pubmed\">26353281</ArticleId></ArticleIdList></Reference><Reference><Citation>K&#xe9;gl B, Krzyzak A. Piecewise Linear Skeletonization Using Principal Curves. IEEE Trans. Pattern Anal. Mach. Intell. 2002;24:59&#x2013;74. doi: 10.1109/34.982884.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/34.982884</ArticleId></ArticleIdList></Reference><Reference><Citation>Cheng Y. Mean shift, mode seeking, and clustering. IEEE Trans. Pattern Anal. Mach. Intell. 1995;17:790&#x2013;799. doi: 10.1109/34.400568.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/34.400568</ArticleId></ArticleIdList></Reference><Reference><Citation>D. Comaniciu, V. Ramesh, P. Meer, The variable bandwidth mean shift and data-driven scale selection, in: Proc. Eighth IEEE Int. Conf. Comput. Vis. ICCV 2001, IEEE Comput. Soc, Vancouver, BC, Canada, 2001: pp. 438&#x2013;445.</Citation></Reference><Reference><Citation>Guo Y, &#x15e;eng&#xfc;r A. A novel image segmentation algorithm based on neutrosophic similarity clustering. Appl. Soft Comput. 2014;25:391&#x2013;398. doi: 10.1016/j.asoc.2014.08.066.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.asoc.2014.08.066</ArticleId></ArticleIdList></Reference><Reference><Citation>Leema N, Nehemiah HK, Kannan A. Neural network classifier optimization using Differential Evolution with Global Information and Back Propagation algorithm for clinical datasets. Appl. Soft Comput. 2016;49:834&#x2013;844. doi: 10.1016/j.asoc.2016.08.001.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.asoc.2016.08.001</ArticleId></ArticleIdList></Reference><Reference><Citation>Xiao M, Zheng WX, Jiang G, Cao J. Undamped Oscillations Generated by Hopf Bifurcations in Fractional-Order Recurrent Neural Networks With Caputo Derivative. IEEE Trans. Neural Netw. Learn. Syst. 2015;26:3201&#x2013;3214. doi: 10.1109/TNNLS.2015.2425734.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TNNLS.2015.2425734</ArticleId><ArticleId IdType=\"pubmed\">25993707</ArticleId></ArticleIdList></Reference><Reference><Citation>L. Rice, E. Wong, J.Z. Kolter, Overfitting in adversarially robust deep learning, in: 2020: pp. 8093&#x2013;8104.</Citation></Reference><Reference><Citation>B.L. Kalman, S.C. Kwasny, Why tanh: choosing a sigmoidal function, in: Proc. Int. Jt. Conf. Neural Netw., IEEE, Baltimore, MD, USA, 1992: pp. 578&#x2013;581.</Citation></Reference><Reference><Citation>R. Hecht-Nielsen, Theory of the Backpropagation Neural Network, Neural Netw. Percept. (1992) 65&#x2013;93.</Citation></Reference><Reference><Citation>Qian N. On the momentum term in gradient descent learning algorithms. Neural Netw. 1999;12:145&#x2013;151. doi: 10.1016/S0893-6080(98)00116-6.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/S0893-6080(98)00116-6</ArticleId><ArticleId IdType=\"pubmed\">12662723</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng T, Zhao J, Gu Y, Wang C, Wu Y, Cheng X, Cai J. H-ProMed: ultrasound image segmentation based on the evolutionary neural network and an improved principal curve. Pattern Recognit. 2022;131:108890. doi: 10.1016/j.patcog.2022.108890.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.patcog.2022.108890</ArticleId></ArticleIdList></Reference><Reference><Citation>Wang J, Wen Y, Gou Y, Ye Z, Chen H. Fractional-order gradient descent learning of BP neural networks with Caputo derivative. Neural Netw. 2017;89:19&#x2013;30. doi: 10.1016/j.neunet.2017.02.007.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.neunet.2017.02.007</ArticleId><ArticleId IdType=\"pubmed\">28278430</ArticleId></ArticleIdList></Reference><Reference><Citation>Bao C, Pu Y, Zhang Y. Fractional-Order Deep Backpropagation Neural Network. Comput. Intell. Neurosci. 2018;2018:1&#x2013;10.</Citation><ArticleIdList><ArticleId IdType=\"pmc\">PMC6051328</ArticleId><ArticleId IdType=\"pubmed\">30065757</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng T, Gu Y, Ye Z, Cheng X, Wang J. A-LugSeg: Automatic and explainability-guided multi-site lung detection in chest X-ray images. Expert Syst. Appl. 2022;198:116873. doi: 10.1016/j.eswa.2022.116873.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1016/j.eswa.2022.116873</ArticleId></ArticleIdList></Reference><Reference><Citation>T. Peng, T.C. Xu, Y. Wang, F. Li, Deep belief network and closed polygonal line for lung segmentation in chest radiographs, Comput. J. (2020).</Citation></Reference><Reference><Citation>Thapa N, Chaudhari M, McManus S, Roy K, Newman RH, Saigo H, Kc DB. DeepSuccinylSite: a deep learning based approach for protein succinylation site prediction. BMC Bioinformatics. 2020;21:63. doi: 10.1186/s12859-020-3342-z.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1186/s12859-020-3342-z</ArticleId><ArticleId IdType=\"pmc\">PMC7178942</ArticleId><ArticleId IdType=\"pubmed\">32321437</ArticleId></ArticleIdList></Reference><Reference><Citation>Peng T, Wang C, Zhang Y, Wang J. H-SegNet: hybrid segmentation network for lung segmentation in chest radiographs using mask region-based convolutional neural network and adaptive closed polyline searching method. Phys. Med. Biol. 2022;67:075006. doi: 10.1088/1361-6560/ac5d74.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1088/1361-6560/ac5d74</ArticleId><ArticleId IdType=\"pubmed\">35287125</ArticleId></ArticleIdList></Reference><Reference><Citation>Cashman D, Perer A, Chang R, Strobelt H. Ablate, Variate, and Contemplate: Visual Analytics for Discovering Neural Architectures. IEEE Trans. Vis. Comput. Graph. 2019;26:863&#x2013;873. doi: 10.1109/TVCG.2019.2934261.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TVCG.2019.2934261</ArticleId><ArticleId IdType=\"pubmed\">31502978</ArticleId></ArticleIdList></Reference><Reference><Citation>Zhou Z, Siddiquee MMR, Tajbakhsh N, Liang J. UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation. IEEE Trans. Med. Imaging. 2020;39:1856&#x2013;1867. doi: 10.1109/TMI.2019.2959609.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TMI.2019.2959609</ArticleId><ArticleId IdType=\"pmc\">PMC7357299</ArticleId><ArticleId IdType=\"pubmed\">31841402</ArticleId></ArticleIdList></Reference><Reference><Citation>Zhao R, Qian B, Zhang X, Li Y, Wei R, Liu Y, Pan Y, Loss Rethinking Dice, for Medical Image Segmentation, in, IEEE Int. Conf. Data Min. ICDM, IEEE, Sorrento, Italy. 2020;2020:851&#x2013;860.</Citation></Reference><Reference><Citation>Lei Y, Tian S, He X, Wang T, Wang B, Patel P, Jani AB, Mao H, Curran WJ, Liu T, Yang X. Ultrasound prostate segmentation based on multidirectional deeply supervised V-Net. Med. Phys. 2019;46:3194&#x2013;3206. doi: 10.1002/mp.13577.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1002/mp.13577</ArticleId><ArticleId IdType=\"pmc\">PMC6625925</ArticleId><ArticleId IdType=\"pubmed\">31074513</ArticleId></ArticleIdList></Reference><Reference><Citation>Wang Y, Dou H, Hu X, Zhu L, Yang X, Xu M, Qin J, Heng P-A, Wang T, Ni D. Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound. IEEE Trans. Med. Imaging. 2019;38:2768&#x2013;2778. doi: 10.1109/TMI.2019.2913184.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1109/TMI.2019.2913184</ArticleId><ArticleId IdType=\"pubmed\">31021793</ArticleId></ArticleIdList></Reference><Reference><Citation>Girum KB, Lalande A, Hussain R, Cr&#xe9;hange G. A deep learning method for real-time intraoperative US image segmentation in prostate brachytherapy. Int. J. Comput. Assist. Radiol. Surg. 2020;15:1467&#x2013;1476. doi: 10.1007/s11548-020-02231-x.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1007/s11548-020-02231-x</ArticleId><ArticleId IdType=\"pubmed\">32691302</ArticleId></ArticleIdList></Reference></ReferenceList></PubmedData></PubmedArticle></PubmedArticleSet>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import entrez\n",
    "from Bio import Entrez \n",
    "\n",
    "# Specify email address (required by NCBI E-utilities)\n",
    "Entrez.email = 'myemail@email.com'\n",
    "\n",
    "# Fetch a particular paper\n",
    "fetch_handle = Entrez.efetch(db='pubmed',id='36729258',retmax=100,rettype='abstract')\n",
    "\n",
    "fetch_handle.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d581b-d979-4c22-8c0b-58fa6f816622",
   "metadata": {},
   "source": [
    "## Code Challenge\n",
    "\n",
    "In the cell above, we hardcoded an id argument to the `Entrez.efetch` function. Can you figure out how to instead use one of the ids in the list we generated in the API exercise above? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (JupyterBook Env)",
   "language": "python",
   "name": "jupyterbook_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}