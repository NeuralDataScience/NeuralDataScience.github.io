{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining cell types by their electrophysiology\n",
    "\n",
    "### The brain has thousands of different types of cells. How do we even begin to tease them apart?\n",
    "\n",
    "We can define neurons by their <b>gene expression patterns</b>, <b>electrophysiology features</b>, and <b>structure</b>. Here, we'll use those three features to compare and contrast cell types in the brain.\n",
    "\n",
    "This notebook will help us investigate specific features in the electrophysiology dataset from the Allen Brain Atlas. Along the way, you'll encounter some concepts about coding in Python.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## Step 1. Set up our coding environment\n",
    "Whenever we start an analysis in Python, we need to be sure to import the necessary code packages. If you're running this notebook on Colab or Binder, the cells below will install packages into your coding environment -- we are *not* installing anything on your computer.\n",
    "\n",
    "### Install the AllenSDK\n",
    "The Allen Institute has compiled a set of code and tools called a **Software Development Kit** (SDK). These tools will help us import and analyze the cell types data. See [Technical Notes](#technical) at the end of this notebook for more information about working with the AllenSDK.\n",
    "\n",
    "><b>Task</b>: Run the cell below, which will install the allensdk into your coding environment.\n",
    "\n",
    "**Technical notes about installing the allensdk**\n",
    "- If you're running this in Colab, you'll also be prompted to **Restart Runtime** after this is completed. Click the **Restart Runtime** button (nothing will happen), and then you're ready to proceed.\n",
    "- If you receive an error or are running this notebook on your local computer, there are additional instructions on how to install the SDK locally <a href=\"http://alleninstitute.github.io/AllenSDK/install.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allensdk imported\n"
     ]
    }
   ],
   "source": [
    "# This will ensure that the AllenSDK is installed.\n",
    "try:\n",
    "    import allensdk\n",
    "    print('allensdk imported')\n",
    "except ImportError as e:\n",
    "    !pip install allensdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task</b>: We also need to make sure that our coding environment has [NumPy](https://numpy.org/), [Pandas](https://pandas.pydata.org/), and [Matplotlib](https://matplotlib.org/) already installed. Run the cell below -- any packages that are missing will be installed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy already installed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas already installed\n",
      "matplotlib already installed\n"
     ]
    }
   ],
   "source": [
    "# This will ensure that NumPy, Pandas, and Matplotlib are installed.\n",
    "try:\n",
    "    import numpy\n",
    "    print('numpy already installed')\n",
    "except ImportError as e:\n",
    "    !pip install numpy\n",
    "try:\n",
    "    import pandas\n",
    "    print('pandas already installed')\n",
    "except ImportError as e:\n",
    "    !pip install pandas  \n",
    "try:\n",
    "    import matplotlib\n",
    "    print('matplotlib already installed')\n",
    "except ImportError as e:\n",
    "    !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common packages\n",
    "Below, we'll `import` a common selection of packages that will help us analyze and plot our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     Type      Data/Info\n",
      "--------------------------------\n",
      "allensdk     module    <module 'allensdk' from '<...>es/allensdk/__init__.py'>\n",
      "matplotlib   module    <module 'matplotlib' from<...>/matplotlib/__init__.py'>\n",
      "np           module    Shape: <function shape at 0x104a084a0>\n",
      "numpy        module    Shape: <function shape at 0x104a084a0>\n",
      "pandas       module    <module 'pandas' from '/o<...>ages/pandas/__init__.py'>\n",
      "pd           module    <module 'pandas' from '/o<...>ages/pandas/__init__.py'>\n",
      "plt          module    <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n"
     ]
    }
   ],
   "source": [
    "# Import our plotting package from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the CellTypesModule from the allensdk\n",
    "With the allensdk installed, we can `import` the **CellTypesCache module**.\n",
    "\n",
    "The CellTypesCache that we're importing provides tools to allow us to get information from the cell types database. We're giving it a **manifest** filename as well. CellTypesCache will create this manifest file, which contains metadata about the cache. If you want, you can look in the cell_types folder in your code directory and take a look at the file.\n",
    "\n",
    "><b>Task</b>: Run the cell below. If you'd like a slightly faster way of working with the raw data files required by this notebook, you can also **uncomment** (remove the `#`) from the `!git` and `%cd` lines below to clone the data from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CellTypesCache imported.\n"
     ]
    }
   ],
   "source": [
    "#Import the \"Cell Types Cache\" from the AllenSDK core package\n",
    "from allensdk.core.cell_types_cache import CellTypesCache\n",
    "\n",
    "#If you're short on time, clone the repository to get the raw data\n",
    "#!git clone https://github.com/ajuavinett/CellTypesLesson.git\n",
    "#%cd CellTypesLesson\n",
    "\n",
    "#Initialize the cache as 'ctc' (cell types cache)\n",
    "ctc = CellTypesCache(manifest_file='cell_types/manifest.json')\n",
    "\n",
    "print('CellTypesCache imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Import Cell Types data\n",
    "\n",
    "Now that we have the module that we need, let's import a raw sweep of the data. The cell below will grab the data for the same experiment you just looked at on the website. This data is in the form of a [**Neuroscience Without Borders** (NWB)](https://www.nwb.org/) file.\n",
    "\n",
    "You can see this same cell [on the Allen Institute website](https://celltypes.brain-map.org/experiment/electrophysiology/474626527).\n",
    "\n",
    "This might take a minute or two. You should wait until the circle in the upper right is <i>not</i> filled (Jupyter Notebook) or you have a green checkmark (Colab) to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m cell_id = \u001b[32m474626527\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get the electrophysiology (ephys) data for that cell\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m data = \u001b[43mctc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ephys_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mData retrieved\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/core/cell_types_cache.py:302\u001b[39m, in \u001b[36mCellTypesCache.get_ephys_data\u001b[39m\u001b[34m(self, specimen_id, file_name)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[33;03mDownload electrophysiology traces for a single cell in the database.\u001b[39;00m\n\u001b[32m    279\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m    and response traces out of an NWB file.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    299\u001b[39m file_name = \u001b[38;5;28mself\u001b[39m.get_cache_path(\n\u001b[32m    300\u001b[39m     file_name, \u001b[38;5;28mself\u001b[39m.EPHYS_DATA_KEY, specimen_id)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_ephys_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecimen_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlazy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m NwbDataSet(file_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/warehouse_cache/cache.py:661\u001b[39m, in \u001b[36mcacheable.<locals>.decor.<locals>.w\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decor.post \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpost in kwargs\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    659\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m] = decor.post\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m result = \u001b[43mCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/warehouse_cache/cache.py:387\u001b[39m, in \u001b[36mCache.cacher\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m    385\u001b[39m         writer(path, data)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         data = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reader:\n\u001b[32m    390\u001b[39m     data = reader(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/queries/cell_types_api.py:325\u001b[39m, in \u001b[36mCellTypesApi.save_ephys_data\u001b[39m\u001b[34m(self, specimen_id, file_name)\u001b[39m\n\u001b[32m    321\u001b[39m criteria = \u001b[33m'\u001b[39m\u001b[33m[id$eq\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m],ephys_result(well_known_files(well_known_file_type[name$eq\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m]))\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    322\u001b[39m     specimen_id, \u001b[38;5;28mself\u001b[39m.NWB_FILE_TYPE)\n\u001b[32m    323\u001b[39m includes = \u001b[33m'\u001b[39m\u001b[33mephys_result(well_known_files(well_known_file_type))\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSpecimen\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                           \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincludes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    331\u001b[39m     file_url = results[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mephys_result\u001b[39m\u001b[33m'\u001b[39m][\n\u001b[32m    332\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mwell_known_files\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mdownload_link\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/queries/rma_api.py:257\u001b[39m, in \u001b[36mRmaApi.model_query\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    218\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Construct and execute a model stage of an RMA query string.\u001b[39;00m\n\u001b[32m    219\u001b[39m \n\u001b[32m    220\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    255\u001b[39m \u001b[33;03m    response, including the normalized query.\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjson_msg_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_query_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/api.py:164\u001b[39m, in \u001b[36mApi.json_msg_query\u001b[39m\u001b[34m(self, url, dataframe)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjson_msg_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, dataframe=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m''' Common case where the url is fully constructed\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03m        and the response data is stored in the 'msg' field.\u001b[39;00m\n\u001b[32m    150\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \u001b[33;03m        returned data; type depends on dataframe option\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataframe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    168\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mdataframe argument is deprecated\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/api.py:204\u001b[39m, in \u001b[36mApi.do_query\u001b[39m\u001b[34m(self, url_builder_fn, json_traversal_fn, *args, **kwargs)\u001b[39m\n\u001b[32m    200\u001b[39m api_url = url_builder_fn(*args, **kwargs)\n\u001b[32m    202\u001b[39m post = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m json_parsed_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretrieve_parsed_json_over_http\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m json_traversal_fn(json_parsed_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/api/api.py:369\u001b[39m, in \u001b[36mApi.retrieve_parsed_json_over_http\u001b[39m\u001b[34m(self, url, post)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m._log.info(\u001b[33m\"\u001b[39m\u001b[33mDownloading URL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, url)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m post \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     data = \u001b[43mjson_utilities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_url_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquote\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                             \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;/?:@&=+$,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    373\u001b[39m     data = json_utilities.read_url_post(url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/allensdk/core/json_utilities.py:118\u001b[39m, in \u001b[36mread_url_get\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m    115\u001b[39m response = urllib_request.urlopen(url)\n\u001b[32m    116\u001b[39m json_string = response.read().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/simplejson/__init__.py:514\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``s`` (a ``str`` or ``unicode`` instance containing a JSON\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03mdocument) to a Python object.\u001b[39;00m\n\u001b[32m    464\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    508\u001b[39m \n\u001b[32m    509\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    511\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    512\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    513\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_decimal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    516\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/simplejson/decoder.py:386\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w, _PY3)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _PY3 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    385\u001b[39m     s = \u001b[38;5;28mstr\u001b[39m(s, \u001b[38;5;28mself\u001b[39m.encoding)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m end = _w(s, end).end()\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/jb_py311/lib/python3.11/site-packages/simplejson/decoder.py:416\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx, _w, _PY3)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m ord0 == \u001b[32m0xef\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m s[idx:idx + \u001b[32m3\u001b[39m] == \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\xef\u001b[39;00m\u001b[38;5;130;01m\\xbb\u001b[39;00m\u001b[38;5;130;01m\\xbf\u001b[39;00m\u001b[33m'\u001b[39m:\n\u001b[32m    415\u001b[39m         idx += \u001b[32m3\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Get the data for one cell (\n",
    "cell_id = 474626527\n",
    "\n",
    "# Get the electrophysiology (ephys) data for that cell\n",
    "data = ctc.get_ephys_data(cell_id)\n",
    "print('Data retrieved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, our NWB file has some built-in **methods** to enable us to pull out a recording sweep. We can access methods of objects like our `data` object by adding a period, and then the method. That's what we're doing below, with `data.get_sweep()`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've chosen a sweep with some action potentials\n",
    "sweep_number = 28\n",
    "\n",
    "sweep_data = data.get_sweep(sweep_number) \n",
    "print('Sweep obtained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Plot a raw sweep of data\n",
    "Now that you've pulled down some data, chosen a cell, and chosen a sweep number, let's plot that data.\n",
    "\n",
    "><b>Task:</b> Run the cell below to get the stimulus and recorded response information from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stimulus trace (in amps) and convert to pA\n",
    "stim_current = sweep_data['stimulus'] * 1e12\n",
    "\n",
    "# Get the voltage trace (in volts) and convert to mV\n",
    "response_voltage = sweep_data['response'] * 1e3\n",
    "\n",
    "# Get the sampling rate and can create a time axis for our data\n",
    "sampling_rate = sweep_data['sampling_rate'] # in Hz\n",
    "timestamps = (np.arange(0, len(response_voltage)) * (1.0 / sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task</b>: In the cell below, use the <code>plt.plot(x,y)</code> to plot our voltage trace.\n",
    ">- You will need to give it two arguments, which are variables we created above: <code>timestamps</code> (x axis) and <code>response_voltage</code>(y).\n",
    "- Without changing the limits on the x-axis, you won't be able to see individual action potentials.\n",
    "- Modify the x-axis using <code>plt.xlim([min,max])</code> to specify the limits (replace <code>min</code> and <code>max</code> with numbers that make sense for this x-axis.\n",
    "- If you'd like to plot the current that was injected into the cell, you can plot <code>stim_current</code> instead of <code>response_voltage.</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw recording here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Plot the morphology of the cell\n",
    "The Cell Types Database also contains **3D reconstructions** of neuronal morphologies. Here, we'll plot the reconstruction of our cell's morphology.\n",
    "\n",
    "*Note*: It will take several minutes to run the cell below, possibly longer over a slow internet connection. Running this cell is optional and can be skipped if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary toolbox\n",
    "from allensdk.core.swc import Marker\n",
    "\n",
    "# Download and open morphology and marker files\n",
    "morphology = ctc.get_reconstruction(cell_id) \n",
    "markers = ctc.get_reconstruction_markers(cell_id) \n",
    "\n",
    "# Set up our plot\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10,10))\n",
    "axes[0].set_aspect('equal')\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Make a line drawing of x-y and y-z views\n",
    "for n in morphology.compartment_list:\n",
    "    for c in morphology.children_of(n):\n",
    "        axes[0].plot([n['x'], c['x']], [n['y'], c['y']], color='black')\n",
    "        axes[1].plot([n['z'], c['z']], [n['y'], c['y']], color='black')\n",
    "\n",
    "# cut dendrite markers\n",
    "dm = [ m for m in markers if m['name'] == Marker.CUT_DENDRITE ]\n",
    "axes[0].scatter([m['x'] for m in dm], [m['y'] for m in dm], color='#3333ff')\n",
    "axes[1].scatter([m['z'] for m in dm], [m['y'] for m in dm], color='#3333ff')\n",
    "\n",
    "# no reconstruction markers\n",
    "nm = [ m for m in markers if m['name'] == Marker.NO_RECONSTRUCTION ]\n",
    "axes[0].scatter([m['x'] for m in nm], [m['y'] for m in nm], color='#333333')\n",
    "axes[1].scatter([m['z'] for m in nm], [m['y'] for m in nm], color='#333333')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[1].set_xlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Analyze pre-computed features\n",
    "\n",
    "The Cell Types Database contains a set of features that have already been computed, which could serve as good starting points for analysis. We can query the database to get these features. Below, we'll use the Pandas package that we imported above to create a **[dataframe](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe)** of our data.\n",
    "\n",
    "><b>Task</b>: Run the cell below. It'll take ~10 seconds. It will print a list of all of the feature available, as well as produce a dataframe, which looks something like an Excel spreadsheet. You can scroll to the right to see many of the different features available in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all electrophysiology features for all cells\n",
    "ephys_features = ctc.get_ephys_features()\n",
    "dataframe = pd.DataFrame(ephys_features).set_index('specimen_id')\n",
    "\n",
    "print('Ephys features available for %d cells:' % len(dataframe))\n",
    "dataframe.head() # Just show the first 5 rows (the head) of our dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the dataframe above, there are many **pre-computed features** available in this dataset. [Here's a glossary](https://docs.google.com/document/d/1YGLwkMTebwrXd_1E817LFbztMjSTCWh83Mlp3_3ZMEo/edit?usp=sharing), in case you're curious.\n",
    "\n",
    "![](https://github.com/ajuavinett/CellTypesLesson/blob/master/docs/ap_features.png?raw=true)\n",
    "\n",
    "Image from the <a href=\"http://help.brain-map.org/download/attachments/8323525/CellTypes_Ephys_Overview.pdf\">Allen Institute Cell Types Database Technical Whitepaper.</a>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the speed of the trough, and the ratio between the upstroke and downstroke of the action potential:\n",
    "- **Action potential fast trough** (<code>fast_trough_v_long_square</code>): Minimum value of the membrane potential in the interval lasting 5 ms after the peak.\n",
    "- **Upstroke/downstroke ratio** (<code>upstroke_downstroke_ratio_long_square</code>)</b>: The ratio between the absolute values of the action potential peak upstroke and the action potential peak downstroke.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created a pandas dataframe of all of these features. Here, we'll assign the columns we're interested to two different **variables**, so that they will contain all of the datapoints we're interested in. We can access different columns of the dataframe by using the syntax `dataframe['column_of_interest']`. The columns of interest here are `fast_trough_v_long_square` and `upstroke_downstroke_ratio_long_square`].\n",
    "\n",
    "><b>Task:</b> Edit and run the cell below to store these columns into our two new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_trough = ...\n",
    "upstroke_downstroke = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task:</b> Create a scatterplot that plots the fast trough (x axis) versus the upstroke-downstroke ratio (y axis). Label your axes accordingly using `plt.xlabel()` and `plt.ylabel()`.\n",
    "    \n",
    "If you need help, see the [`plt.scatter()` documentation](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your scatterplot here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there may be roughly two clusters in the data above. Maybe they relate to whether the cells are presumably excitatory (spiny) cells or inhibitory (aspiny) cells. Let's query the API and split up the two sets to see.\n",
    "\n",
    "><b>Task:</b> The cell below will dig up the dendrite type of these cells and add that to our dataframe. Then, it'll create our same scatterplot, where each dot is colored by dendrite type. All you need to do is run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about our cells' dendrites\n",
    "cells = ctc.get_cells()\n",
    "full_dataframe = dataframe.join(pd.DataFrame(cells).set_index('id'))\n",
    "\n",
    "# Create a dataframe for spiny cells, and a dataframe for aspiny cells\n",
    "spiny_df = full_dataframe[full_dataframe['dendrite_type'] == 'spiny']\n",
    "aspiny_df = full_dataframe[full_dataframe['dendrite_type'] == 'aspiny']\n",
    "\n",
    "# Create our plot! Calling scatter twice like this will draw both of these on the same plot.\n",
    "plt.scatter(spiny_df['fast_trough_v_long_square'],spiny_df['upstroke_downstroke_ratio_long_square'])\n",
    "plt.scatter(aspiny_df['fast_trough_v_long_square'],aspiny_df['upstroke_downstroke_ratio_long_square'])\n",
    "\n",
    "plt.ylabel('upstroke-downstroke ratio')\n",
    "plt.xlabel('fast trough depth (mV)')\n",
    "plt.legend(['Spiny','Aspiny'])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like these two clusters do partially relate to the dendritic type. Cells with spiny dendrites (which are typically excitatory cells) have a big ratio of upstroke:downstroke, and a more shallow trough (less negative). Cells with aspiny dendrites (typically inhibitory cells) are a little bit more varied. But </i>only</i> aspiny cells have a low upstroke:downstroke ratio and a deeper trough (more negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Compare waveforms\n",
    "Let's take a closer look at the action potentials of these cells to see what these features actually mean for the action potential waveform by choosing one of the cells with the highest upstroke:downstroke ratio. Our first line of code, where it says `dataframe.sort_values()` is the code that will arrange our dataframe by the **upstroke_downstroke_ratio_long_square** column.\n",
    "\n",
    "This first time around, we'll organize it so that the highest ratio is at the top (`ascending=False`). This is an example of a **boolean** in Python. You can change this to say `ascending=True` if you want to sort with *lowest* ratio at the top.\n",
    "\n",
    "><b>Task</b>: Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe and reassign\n",
    "sorted_dataframe = dataframe.sort_values('upstroke_downstroke_ratio_long_square',ascending=False)\n",
    "\n",
    "# Assign one of the top cells in our dataframe (default = 2) and the ratio to different variables\n",
    "specimen_id = sorted_dataframe.index[2]\n",
    "ratio = sorted_dataframe.iloc[2]['upstroke_downstroke_ratio_long_square']\n",
    "\n",
    "# Print our results so that we can see them\n",
    "print('Specimen ID: ' + str(specimen_id) + ' with upstroke-downstroke ratio: ' + str(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a closer look at the action potential for that cell by grabbing a raw sweep of recording from it, just like we did above.\n",
    "\n",
    "><b>Task:</b> Run the cell below. This may take a minute or so. *Note*: You may receive a \"H5pyDeprecationWarning,\" but you can ignore this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data for our specimen\n",
    "upstroke_data = ctc.get_ephys_data(specimen_id)\n",
    "\n",
    "# Get one sweep for our specimen (I've already handselected a gorgeous one for you, 45)\n",
    "upstroke_sweep = upstroke_data.get_sweep(45) \n",
    "\n",
    "# Get the current & voltage traces\n",
    "current = upstroke_sweep['stimulus'] * 1e12 # in A, converted to pA\n",
    "voltage = upstroke_sweep['response'] * 1e3 # converted to mV!\n",
    "\n",
    "# Get the time stamps for our voltage trace\n",
    "timestamps = (np.arange(0, len(voltage)) * (1.0 / upstroke_sweep['sampling_rate']))\n",
    "\n",
    "print('Sweep obtained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task:</b> Plot the sweep we obtained above. <i>Hint</i>: You'll want to use `plt.plot(x,y)` where `x` is the `timestamps` and `y` is the `voltage`. Be sure to give your plot accurate labels as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new sweep here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task</b> Generate a similar plot for a cell with a <b>low</b> upstroke ratio. Similiar to above, zoom in on the x axis so that you can actually see the shape of the action potential waveform.\n",
    "\n",
    "><b>Hint</b>: You only need to change <i>one</i> value in all of the code in this step in order to make this change. How did we arrange our dataframe at first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you'll hopefully see, even that one feature, upstroke:downstroke ratio, means the shape of the action potential is dramatically different. The other feature we looked at above, size of the trough, is highly correlated with upstroke:downstroke. You can see that by comparing the two cells here. Cells with high upstroke:downstroke tend to have less negative troughs (undershoots) after the action potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Compare cell types\n",
    "Let's get out of the action potential weeds a bit. What if we want to know a big picture thing, such as are *human cells different than mouse cells?* Or *how are excitatory cells different from inhibitory cells?*  To ask these questions, we can pull out the data for two different cell types, defined by their species, dendrite type, or transgenic line.\n",
    "\n",
    "**About Transgenic Cre Lines.** The Allen Institute for Brain Science uses transgenic mouse lines that have Cre-expressing cells to mark specific types of cells in the brain. This technology is called the **Cre-Lox system**, and is a common way in neuroscience (and some other fields) to target cells based on their expression of specific genetic promotors. For more information about Cre/Lox technology, see [this website](https://old.abmgood.com/marketing/knowledge_base/Cre-Lox_Recombination.php). Information about the different Cre lines that are available can be found in [this glossary](https://docs.google.com/document/d/1ZMMZgc7cS5BHhoWNqzjw95BdxOuj5wrYl9I7PV2HeUI/edit?usp=sharing) or on the [Allen Institute's website](http://connectivity.brain-map.org/transgenic).\n",
    "\n",
    "**For this final step, it's up to you to choose which cell types to compare.** You'll also decide which pre-computed feature to compare between these cell types.\n",
    "\n",
    "- If you'd like to compare cells from different **species**, the column name is `species`.\n",
    "- If you'd like to compare **spiny vs. aspiny cells**, the column name is `dendrite_type`.\n",
    "- If you'd like to compare two **transgenic lines** (mouse cells only), the column name is `transgenic_line`. What if we want to know whether different genetically-identified cells have different intrinsic physiology?\n",
    "- If you'd like to compare two **disease states** (human cells only; samples taken from people either with epilepsy and brain tumors), the column name is `disease_state`.\n",
    "\n",
    "\n",
    ">**Task**: Assign `column_name` below to the name of your column to see the unique values in that column. Make sure your column is a **string**, in other words, it should be in single  quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your column name below\n",
    "column_name = ...\n",
    "\n",
    "print(full_dataframe[column_name].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the possible values in your column, create two separate dataframes by **subsetting** the dataframe below. Assign `celltype_1` and `celltype_2` to the names of your cell types, for example 'spiny' and 'aspiny'. Make sure your cell type names are in quotes (they should be strings) and *exactly* match what is found in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your cell type variables below\n",
    "celltype_1 = ...\n",
    "celltype_2 = ...\n",
    "\n",
    "celltype_1_df = full_dataframe[full_dataframe[column_name] == celltype_1]\n",
    "celltype_2_df = full_dataframe[full_dataframe[column_name] == celltype_2]\n",
    "\n",
    "print(\"Type 1 # Cells: %d\" % len(celltype_1_df))\n",
    "print(\"Type 2 # Cells: %d\" % len(celltype_2_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by plotting a distribution of the recorded resting membrane potential (`vrest`) for one cell type versuss the other cell type.\n",
    "\n",
    ">**Task**: Run the cell below to plot a histogram to compare one pre-computedd feature of your choice between your two cell types.\n",
    "\n",
    "- Note that the distribution is normalized by the total count (`density=True`), since there may be very different numbers of cells for your two cell types. You can set `density` to false to plot the raw numbers of cells.\n",
    "- You can also specify the number of bins with `bins= < #bins > `.\n",
    "- Look through the [`plt.hist()` documentation](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.hist.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Change your feature below.\n",
    "feature = 'vrest'\n",
    "\n",
    "# Plot the histogram, with density = True \n",
    "plt.hist([celltype_1_df[feature],celltype_2_df[feature]],density = True)\n",
    "\n",
    "# Change the x label below:\n",
    "plt.xlabel('< feature name >')\n",
    "plt.ylabel('Normalized Number of Cells')\n",
    "plt.legend(['Cell Type 1','Cell Type 2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Task</b>: Choose a different feature to compare between your cell types, and rerun the plot above. Use the documentation below to get the exact name of the feature (in parentheses), and change the x label axis so that we know what you're plotting.  Right click to save your image when you're done.\n",
    "\n",
    "Here are a few additional pre-computed features you might consider comparing (you can find a complete glossary [here](https://docs.google.com/document/d/1YGLwkMTebwrXd_1E817LFbztMjSTCWh83Mlp3_3ZMEo/edit?usp=sharing)):\n",
    "\n",
    "- <b>Tau (<code>tau</code>)</b>: time constant of the membrane in milliseconds\n",
    "- <b>Adapation ratio (<code>adaptation</code>)</b>: The rate at which firing speeds up or slows down during a stimulus<br>\n",
    "- <b>Average ISI (<code>avg_isi</code>)</b>: The mean value of all interspike intervals in a sweep<br>\n",
    "- **Slope of f/I curve** (<code>f_i_curve_slope</code>)</b>: slope of the curve between firing rate (f) and current injected<br>\n",
    "- **Input Resistance** (<code>input_resistance_mohm</code>)</b>: The input resistance of the cell, in megaohms.<br>\n",
    "- **Voltage of after-hyperpolarization** (<code>trough_v_short_square</code>)</b>: minimum value of the membrane potential during the after-hyperpolarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Task</b>: It's more common to plot summary statistics like a mean or median, so let's compare our two cell types with a boxplot. To do so, we can use `plt.boxplot()` ([Documentation here](https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.boxplot.html)). The code below is already set up for you -- just run it and edit your labels as necessary. Right click to save the plot when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot creation lines below\n",
    "plt.boxplot([celltype_1_df[feature],celltype_2_df[feature]])\n",
    "plt.ylabel('< your label here > ') # y-axis label\n",
    "plt.xticks([1, 2], ['Cell Type 1','Cell Type 2'])\n",
    "\n",
    "# Plot title -- be sure to update!\n",
    "plt.title('< your title here > ')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for today -- great work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "print('Nice work!')\n",
    "HTML('<img src=\"https://media.giphy.com/media/xUOwGhOrYP0jP6iAy4/giphy.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## Technical notes & credits\n",
    "\n",
    "This notebook demonstrates most of the features of the AllenSDK that help manipulate data in the Cell Types Database.  The main entry point will be through the `CellTypesCache` class. `CellTypesCache` is responsible for downloading Cell Types Database data to a standard directory structure on your hard drive.  If you use this class, you will not have to keep track of where your data lives, other than a root directory.\n",
    "\n",
    "Much more information can be found in the <a href=\"http://help.brain-map.org/download/attachments/8323525/CellTypes_Ephys_Overview.pdf\">Allen Brain Atlas whitepaper</a> as well as in their <a href=\"http://alleninstitute.github.io/AllenSDK/cell_types.html\">GitHub documentation</a>.\n",
    "\n",
    "This file modified from <a href='https://alleninstitute.github.io/AllenSDK/_static/examples/nb/cell_types.html'>this</a> notebook.\n",
    "\n",
    "In case you're curious, <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.html \">here's documentation</a> for plotting pandas series (which we do quite a bit above). You can always Google questions you have!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}